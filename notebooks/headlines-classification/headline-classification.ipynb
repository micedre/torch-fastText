{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f1842c-6389-4a31-a8a5-c45fb0c29e26",
   "metadata": {},
   "source": [
    "# News Headline Classification with torchfasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae723b7f-7291-4d94-8509-81b74c8c1dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.6.1)\n",
      "Requirement already satisfied: torchfasttext in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.0.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: captum in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.8.0)\n",
      "Collecting mlflow (from -r requirements.txt (line 6))\n",
      "  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: pytorch-lightning>=2.4.0 in /usr/local/lib/python3.12/site-packages (from torchfasttext->-r requirements.txt (line 2)) (2.5.1.post0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 3)) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/site-packages (from captum->-r requirements.txt (line 5)) (3.10.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/site-packages (from captum->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/site-packages (from captum->-r requirements.txt (line 5)) (2.7.0)\n",
      "Collecting mlflow-skinny==2.22.0 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting Flask<4 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 6)) (3.1.6)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/site-packages (from mlflow->-r requirements.txt (line 6)) (2.2.3)\n",
      "Collecting pyarrow<20,>=4.0.0 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r requirements.txt (line 6))\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading databricks_sdk-0.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (3.1.44)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting packaging (from captum->-r requirements.txt (line 5))\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3,>=1.10.8 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/site-packages (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (4.13.2)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow->-r requirements.txt (line 6)) (2.4.0)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/site-packages (from Flask<4->mlflow->-r requirements.txt (line 6)) (3.0.2)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (5.0.2)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/site-packages (from graphene<4->mlflow->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->captum->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/site-packages (from matplotlib->captum->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/site-packages (from matplotlib->captum->-r requirements.txt (line 5)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->captum->-r requirements.txt (line 5)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/site-packages (from matplotlib->captum->-r requirements.txt (line 5)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->captum->-r requirements.txt (line 5)) (3.2.3)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas<3->mlflow->-r requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas<3->mlflow->-r requirements.txt (line 6)) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (2025.4.26)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow->-r requirements.txt (line 6))\n",
      "  Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow->-r requirements.txt (line 6)) (1.17.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (1.7.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/site-packages (from pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (0.14.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (1.20.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.4.0->torchfasttext->-r requirements.txt (line 2)) (80.7.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.12/site-packages (from torch>=1.10->captum->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.10->captum->-r requirements.txt (line 5)) (1.3.0)\n",
      "Downloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading databricks_sdk-0.53.0-py3-none-any.whl (700 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m700.2/700.2 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Downloading google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl (320 kB)\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.9/603.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: zipp, werkzeug, uvicorn, typing-inspection, sqlparse, pydantic-core, pyasn1, pyarrow, protobuf, packaging, markdown, Mako, itsdangerous, greenlet, graphql-core, deprecated, cloudpickle, cachetools, blinker, annotated-types, starlette, sqlalchemy, rsa, pydantic, pyasn1-modules, importlib_metadata, gunicorn, graphql-relay, Flask, docker, opentelemetry-api, graphene, google-auth, fastapi, alembic, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "\u001b[2K  Attempting uninstall: pyarrow0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/40\u001b[0m [pyasn1]e]\n",
      "\u001b[2K    Found existing installation: pyarrow 20.0.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/40\u001b[0m [pyasn1]\n",
      "\u001b[2K    Uninstalling pyarrow-20.0.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/40\u001b[0m [pyasn1]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-20.0.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/40\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: packaging0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/40\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/40\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling packaging-25.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/40\u001b[0m [packaging]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/40\u001b[0m [packaging]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/40\u001b[0m [mlflow] [mlflow] [mlflow-skinny]]c-conventions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.1 Mako-1.3.10 alembic-1.15.2 annotated-types-0.7.0 blinker-1.9.0 cachetools-5.5.2 cloudpickle-3.1.1 databricks-sdk-0.53.0 deprecated-1.2.18 docker-7.1.0 fastapi-0.115.12 google-auth-2.40.1 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.2 gunicorn-23.0.0 importlib_metadata-8.6.1 itsdangerous-2.2.0 markdown-3.8 mlflow-2.22.0 mlflow-skinny-2.22.0 opentelemetry-api-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 packaging-24.2 protobuf-6.31.0 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.4 pydantic-core-2.33.2 rsa-4.9.1 sqlalchemy-2.0.41 sqlparse-0.5.3 starlette-0.46.2 typing-inspection-0.4.0 uvicorn-0.34.2 werkzeug-3.1.3 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52ecf6-561c-4a62-a04a-b6ff8b6e1ea7",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f5b928-cc56-456b-9be0-d7308496b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"https://minio.lab.sspcloud.fr/h4njlg/public/ag_news_full_1M.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e63111-4096-4a9d-8690-3716d6c42331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "World                        186896\n",
       "Sci/Tech                     154869\n",
       "Business                     146646\n",
       "Entertainment                137437\n",
       "Italia                       133428\n",
       "Top News                     126514\n",
       "Sports                       118131\n",
       "Europe                        90573\n",
       "Top Stories                   61579\n",
       "U.S.                          47707\n",
       "Health                        42629\n",
       "Software and Developement     19041\n",
       "Toons                          8016\n",
       "Music Feeds                    7632\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8038c66-ab3e-41ac-8404-eb4a945f03f9",
   "metadata": {},
   "source": [
    "## Prepping the data \n",
    "\n",
    "\n",
    "Let's merge some categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "617f4060-c757-45d7-bab0-95ac2921d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cat(cat):\n",
    "    if cat in ['World', 'Top News', 'Europe', 'Italia', 'U.S.', 'Top Stories']:\n",
    "        return 'World News'\n",
    "    if cat in ['Sci/Tech', 'Software and Developement', 'Toons', 'Health', 'Music Feeds']:\n",
    "        return 'Tech and Stuff'\n",
    "    return cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c6abe3c-815a-47f2-9f2c-b6b4c7cd55af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593220</th>\n",
       "      <td>Sgrena, Prodi sforzo congiunto</td>\n",
       "      <td>Volonta compatta per fare tutto cio che ci e p...</td>\n",
       "      <td>World News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97506</th>\n",
       "      <td>Oracle Ruling May Embolden Dealmakers (Reuters)</td>\n",
       "      <td>Reuters - A federal judge may have sent a gift...</td>\n",
       "      <td>Tech and Stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919916</th>\n",
       "      <td>Comic for 16 Jun 2007</td>\n",
       "      <td>&lt;img src=\"http://www.comics.com/creators/wizar...</td>\n",
       "      <td>Tech and Stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676380</th>\n",
       "      <td>Profit taking drives European stocks lower \\n ...</td>\n",
       "      <td>FT.com - European equities turned positive by ...</td>\n",
       "      <td>World News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980182</th>\n",
       "      <td>Throttle teacher is struck off</td>\n",
       "      <td>The General Teaching Council of Wales strikes ...</td>\n",
       "      <td>World News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "593220                     Sgrena, Prodi sforzo congiunto   \n",
       "97506     Oracle Ruling May Embolden Dealmakers (Reuters)   \n",
       "919916                              Comic for 16 Jun 2007   \n",
       "676380  Profit taking drives European stocks lower \\n ...   \n",
       "980182                     Throttle teacher is struck off   \n",
       "\n",
       "                                              description  category_final  \n",
       "593220  Volonta compatta per fare tutto cio che ci e p...      World News  \n",
       "97506   Reuters - A federal judge may have sent a gift...  Tech and Stuff  \n",
       "919916  <img src=\"http://www.comics.com/creators/wizar...  Tech and Stuff  \n",
       "676380  FT.com - European equities turned positive by ...      World News  \n",
       "980182  The General Teaching Council of Wales strikes ...      World News  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_final'] = df['category'].apply(lambda x: merge_cat(x))\n",
    "df['category_final'].value_counts()\n",
    "\n",
    "df[['title','description','category_final']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17494dd8-9be4-4700-b1a1-85e4cfd7ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_encoder = LabelEncoder()\n",
    "\n",
    "df['cat'] = cat_encoder.fit_transform(df['category_final'])\n",
    "df['title_headline'] = df['title']\n",
    "\n",
    "news_train, news_test = train_test_split(df, stratify=df['cat'], test_size=0.10, shuffle=True, random_state=42)\n",
    "\n",
    "X = news_train['title_headline']\n",
    "y = news_train['cat']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523c462-bf7d-46df-96ca-c7cac35a8909",
   "metadata": {},
   "source": [
    "## Training a basic model \n",
    "\n",
    "Predic `category_final` from `title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dffd6bab-27c3-4f3e-89ef-6ee4f3feeaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 08:04:58 - torchFastText.utilities.checkers - No categorical_vocabulary_sizes. It will be inferred later.\n",
      "2025-05-21 08:04:58 - torchFastText.model.pytorch_model - num_rows is different from the number of tokens in the tokenizer. Using provided num_rows.\n",
      "2025-05-21 08:04:58 - torchFastText.torchFastText - No scheduler parameters provided. Using default parameters (suited for ReduceLROnPlateau).\n",
      "2025-05-21 08:04:58 - torchFastText.datasets.dataset - Creating DataLoader with 12 workers.\n",
      "2025-05-21 08:04:58 - torchFastText.datasets.dataset - Creating DataLoader with 12 workers.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model       | FastTextModel      | 7.9 M  | train\n",
      "1 | loss        | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy_fn | MulticlassAccuracy | 0      | train\n",
      "-----------------------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.625    Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 21067/27024 [05:10<01:27, 67.79it/s, v_num=3, train_loss_step=0.543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "Exception in thread Thread-12 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/local/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 61, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/usr/local/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/connection.py\", line 525, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/connection.py\", line 962, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/optim/adam.py:225\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchFastText/model/lightning_module.py:74\u001b[39m, in \u001b[36mFastTextModule.training_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m.log(\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m, loss, on_epoch=\u001b[38;5;28;01mTrue\u001b[39;00m, on_step=\u001b[38;5;28;01mTrue\u001b[39;00m, prog_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m accuracy = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mself\u001b[39m.log(\u001b[33m\"\u001b[39m\u001b[33mtrain_accuracy\u001b[39m\u001b[33m\"\u001b[39m, accuracy, on_epoch=\u001b[38;5;28;01mTrue\u001b[39;00m, on_step=\u001b[38;5;28;01mFalse\u001b[39;00m, prog_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchmetrics/metric.py:315\u001b[39m, in \u001b[36mMetric.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28mself\u001b[39m._forward_cache = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_cache\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchmetrics/metric.py:384\u001b[39m, in \u001b[36mMetric._forward_reduce_state_update\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m batch_val = \u001b[38;5;28mself\u001b[39m.compute()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchmetrics/metric.py:549\u001b[39m, in \u001b[36mMetric._wrap_update.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchmetrics/classification/stat_scores.py:347\u001b[39m, in \u001b[36mMulticlassStatScores.update\u001b[39m\u001b[34m(self, preds, target)\u001b[39m\n\u001b[32m    344\u001b[39m tp, fp, tn, fn = _multiclass_stat_scores_update(\n\u001b[32m    345\u001b[39m     preds, target, num_classes, \u001b[38;5;28mself\u001b[39m.top_k, \u001b[38;5;28mself\u001b[39m.average, \u001b[38;5;28mself\u001b[39m.multidim_average, \u001b[38;5;28mself\u001b[39m.ignore_index\n\u001b[32m    346\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchmetrics/classification/stat_scores.py:79\u001b[39m, in \u001b[36m_AbstractStatScores._update_state\u001b[39m\u001b[34m(self, tp, fp, tn, fn)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m.fp = \u001b[38;5;28mself\u001b[39m.fp + fp \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [*\u001b[38;5;28mself\u001b[39m.fp, fp]\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtn\u001b[49m = \u001b[38;5;28mself\u001b[39m.tn + tn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.tn, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [*\u001b[38;5;28mself\u001b[39m.tn, tn]\n\u001b[32m     80\u001b[39m \u001b[38;5;28mself\u001b[39m.fn = \u001b[38;5;28mself\u001b[39m.fn + fn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.fn, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [*\u001b[38;5;28mself\u001b[39m.fn, fn]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchmetrics/metric.py:800\u001b[39m, in \u001b[36mMetric.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.compute: Callable = \u001b[38;5;28mself\u001b[39m._wrap_compute(\u001b[38;5;28mself\u001b[39m.compute)  \u001b[38;5;66;03m# type: ignore[method-assign]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, value: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    801\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Overwrite default method to prevent specific attributes from being set by user.\"\"\"\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      5\u001b[39m torchft_model = torchFastText( \n\u001b[32m      6\u001b[39m         num_tokens=\u001b[32m2000\u001b[39m,\n\u001b[32m      7\u001b[39m         embedding_dim=\u001b[32m50\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m         sparse=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mtorchft_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m          \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m          \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m          \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m          \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m          \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m          \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m          \u001b[49m\u001b[43mtrainer_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43menable_progress_bar\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchFastText/torchFastText.py:649\u001b[39m, in \u001b[36mtorchFastText.train\u001b[39m\u001b[34m(self, X_train, y_train, X_val, y_val, num_epochs, batch_size, cpu_run, num_workers, optimizer, optimizer_params, lr, scheduler, patience_scheduler, loss, patience_train, verbose, trainer_params)\u001b[39m\n\u001b[32m    647\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mLaunching training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    648\u001b[39m     start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    651\u001b[39m     end = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from torchFastText import torchFastText\n",
    "import numpy as np\n",
    "\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "mlf_logger = MLFlowLogger(experiment_name=\"ag_headline_classification\")\n",
    "\n",
    "torchft_model = torchFastText( \n",
    "        num_tokens=2000,\n",
    "        embedding_dim=50,\n",
    "        min_count=2,\n",
    "        min_n=2,\n",
    "        max_n=3,\n",
    "        len_word_ngrams=4,\n",
    "        sparse=False,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "torchft_model.train(\n",
    "          np.asarray(X_train),\n",
    "          np.asarray(y_train),\n",
    "          np.asarray(X_test),\n",
    "          np.asarray(y_test),\n",
    "          lr=0.01,\n",
    "          num_epochs=5,\n",
    "          batch_size=32,\n",
    "          trainer_params={'enable_progress_bar': True}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5cc968-8838-4a48-8107-95d27bee0186",
   "metadata": {},
   "source": [
    "## Eval the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c5d07-b3eb-4826-9f7f-ac2d4984e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    " cat_encoder.inverse_transform(torchft_model.predict(np.asarray(['Superstar died at 20 in hotel room']))[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6092417-9792-4aa4-984e-c0527e9eb785",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredictions,_ = torchft_model.predict(np.asarray(news_test[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mtitle_headline\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m]))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mpredictions_decoded = cat_encoder.inverse_transform(predictions.reshape(-1))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint (f\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAccuracy : \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43m(predictions_decoded.reshape(-1) == news_test[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mcategory_final\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m]).mean():0.2\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2547\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2546\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2550\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/IPython/core/magics/execution.py:1390\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1388\u001b[39m st = clock2()\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1392\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchFastText/torchFastText.py:765\u001b[39m, in \u001b[36mtorchFastText.predict\u001b[39m\u001b[34m(self, X, top_k, preprocess, verbose)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    763\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pytorch_model.no_cat_var == \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreprocess\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchFastText/model/pytorch_model.py:286\u001b[39m, in \u001b[36mFastTextModel.predict\u001b[39m\u001b[34m(self, text, categorical_variables, top_k, explain, preprocess)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28mself\u001b[39m.eval()\n\u001b[32m    284\u001b[39m batch_size = \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m indices_batch, id_to_token_dicts, token_to_id_dicts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreprocess\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m padding_index = (\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m.tokenizer.get_buckets() + \u001b[38;5;28mself\u001b[39m.tokenizer.get_nwords()\n\u001b[32m    292\u001b[39m )  \u001b[38;5;66;03m# padding index, the integer value of the padding token\u001b[39;00m\n\u001b[32m    294\u001b[39m padded_batch = torch.nn.utils.rnn.pad_sequence(\n\u001b[32m    295\u001b[39m     indices_batch,\n\u001b[32m    296\u001b[39m     batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    297\u001b[39m     padding_value=padding_index,\n\u001b[32m    298\u001b[39m )  \u001b[38;5;66;03m# (batch_size, seq_len) - Tokenized (int) + padded text\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchFastText/datasets/tokenizer.py:296\u001b[39m, in \u001b[36mNGramTokenizer.tokenize\u001b[39m\u001b[34m(self, text, text_tokens, preprocess)\u001b[39m\n\u001b[32m    294\u001b[39m token_to_id_dicts = []\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     all_ind, id_to_token, token_to_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43msentence\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# tokenize and convert to token indices\u001b[39;00m\n\u001b[32m    299\u001b[39m     tokenized_text.append(all_ind)\n\u001b[32m    300\u001b[39m     id_to_token_dicts.append(id_to_token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torchFastText/datasets/tokenizer.py:258\u001b[39m, in \u001b[36mNGramTokenizer.indices_matrix\u001b[39m\u001b[34m(self, sentence)\u001b[39m\n\u001b[32m    255\u001b[39m gram_hashes = \u001b[38;5;28mtuple\u001b[39m(word_hashes[i : i + n])\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# Compute n-gram ID\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m word_ngram_id = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_word_ngram_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgram_hashes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# Store gram and its ID\u001b[39;00m\n\u001b[32m    263\u001b[39m gram = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(words[i : i + n])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions,_ = torchft_model.predict(np.asarray(news_test['title_headline']))\n",
    "predictions_decoded = cat_encoder.inverse_transform(predictions.reshape(-1))\n",
    "print (f\"Accuracy : {(predictions_decoded.reshape(-1) == news_test['category_final']).mean():0.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e850465-df43-4f0f-869f-26775ac513e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Accuracy : {(predictions_decoded.reshape(-1) == news_test['category_final']).mean():0.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
